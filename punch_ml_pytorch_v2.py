# -*- coding: utf-8 -*-
"""punch-ml-pytorch-v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uU0WL2WKHGEnL7LGVyS-tO8megZBRwOh

# 0. Settings
"""

# default values
PUNCH_TYPES = {
    "None": 0,
    "Straight": 1,
    "Hook": 2,
    "Body": 3,
    "Uppercut": 4,
}

# values for model training
INPUT_SIZE = 3
HIDDEN_SIZE = 10
NUM_LAYERS = 1
WINDOW_SIZE = 20


# values for preparing data
MAX_DATA_NUMBER = 20 # file counts
ACCELERATION_DATA_TYPE = "Acceleration" # "Acceleration" for "Raw Acceleration"

"""# 1. Preparing Model"""

import torch
import torch.nn as nn
import torch.nn.functional as F

device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')

class PunchGRUModel(nn.Module):
  def __init__(self, input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, num_classes=len(PUNCH_TYPES)):
    super(PunchGRUModel, self).__init__()
    self.hidden_size = hidden_size
    self.num_layers = num_layers

    # a layer that puts the accelerometer value into tanh function, this layer makes the accelerometer value from -1 ~ 1
    self.tanh = nn.Tanh()
    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
    self.fc = nn.Linear(hidden_size, num_classes)

  def forward(self, x, h=None):
    # x: (batch, seq_len, input_size)
    x = self.tanh(x)
    out, h = self.gru(x, h)
    logits = self.fc(out)
    return logits, h

"""# 2. Preparing Data"""

import pandas as pd

raw_datas = []

# Columns
# Index,Time,Raw Acceleration X,Raw Acceleration Y,Raw Acceleration Z,Acceleration X,Acceleration Y,Acceleration Z,Angular Velocity X,Angular Velocity Y,Angular Velocity Z,Orientation X,Orientation Y,Orientation Z,Punch Type

for i in range(1, MAX_DATA_NUMBER + 1):
  try:
    data = pd.read_csv(f"../punch-assets/datas/{i}.csv")
    data["Punch Index"] = data["Punch Type"].map(PUNCH_TYPES).fillna(0).astype(int)
    raw_datas.append(data)
  except:
    print(f"No data for {i}.csv")

import numpy as np
from sklearn.model_selection import train_test_split

datas = []
targets = []

for data in raw_datas:
  x = data[ACCELERATION_DATA_TYPE + " X"].values
  y = data[ACCELERATION_DATA_TYPE + " Y"].values
  z = data[ACCELERATION_DATA_TYPE + " Z"].values
  punch = data['Punch Index'].values

  for i in range(WINDOW_SIZE, len(data) + 1):
    datas.append(np.array([
        x[i-WINDOW_SIZE:i],
        y[i-WINDOW_SIZE:i],
        z[i-WINDOW_SIZE:i],
    ]).T)
    targets.append(punch[i-WINDOW_SIZE:i])

X = np.array(datas, dtype=np.float32)
y = np.array(targets)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


train_loader = torch.utils.data.DataLoader(
    torch.utils.data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),
    batch_size=64,
    shuffle=True
)

test_loader = torch.utils.data.DataLoader(
    torch.utils.data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test)),
    batch_size=64,
    shuffle=False
)

for data, target in train_loader:
  print(data.shape, target.shape)
  break

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)

"""# 3. Compiling Model"""

def summary_custom(model):
    print(f"{'Layer':<40} {'Shape':<30} {'Param #':>10}")
    print("=" * 82)

    total_params = 0
    trainable_params = 0

    for name, param in model.named_parameters():
        param_shape = tuple(param.shape)
        param_count = param.numel()
        total_params += param_count
        if param.requires_grad:
            trainable_params += param_count

        print(f"{name:<40} {str(param_shape):<30} {param_count:>10}")

    print("=" * 82)
    print(f"{'Total params:':<40} {total_params:>30}")
    print(f"{'Trainable params:':<40} {trainable_params:>30}")
    print(f"{'Non-trainable params:':<40} {total_params - trainable_params:>30}")

print(f"Using Device : {device}")

# model = PUNCH_ML().to(device)
model = PunchGRUModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

summary_custom(model)

"""# 4. Training Model"""

best_loss = float('inf')
epochs = 500
patience = 5
counter = 0

train_loss = []
train_accuracy = []
val_loss = []
val_accuracy = []

for epoch in range(epochs):
    model.train()

    total_train_loss = 0.0
    total_train_correct = 0
    total_train_samples = 0

    for data, target in train_loader:
        data = data.to(device, dtype=torch.float32)
        target = target.to(device)

        optimizer.zero_grad()
        outputs, _ = model(data)

        # reshaping results
        outputs = outputs.view(-1, outputs.size(-1))
        target = target.view(-1)

        # update parameters
        loss = criterion(outputs, target)
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total_train_correct += (predicted == target).sum().item()
        total_train_samples += target.size(0)

    train_loss.append(total_train_loss / len(train_loader))
    train_accuracy.append(total_train_correct / total_train_samples)

    total_val_loss = 0.0
    total_val_correct = 0
    total_val_samples = 0




    model.eval()
    for data, target in test_loader:
        data = data.to(device, dtype=torch.float32)
        target = target.to(device)

        outputs, _ = model(data)
        outputs = outputs.view(-1, outputs.size(-1))
        target = target.view(-1)

        loss = criterion(outputs, target)

        total_val_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total_val_correct += (predicted == target).sum().item()
        total_val_samples += target.size(0)

    val_loss.append(total_val_loss / len(test_loader))
    val_accuracy.append(total_val_correct / total_val_samples)


    if total_val_loss < best_loss:
        best_loss = total_val_loss
        counter = 0
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping triggered.")
            break

    print(f"Epoch {epoch+1:3d}/{epochs} | Train Loss: {train_loss[-1]:.4f} | Train Accuracy: {train_accuracy[-1]*100:.2f}% | Validation Loss: {val_loss[-1]:.4f} | Validataion Accuracy: {val_accuracy[-1]*100:.2f}%")

"""# 5. Evaluating Model"""

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))

# Loss 그래프
plt.subplot(1, 2, 1)
plt.title(f"GRU_{INPUT_SIZE}I_{HIDDEN_SIZE}H_{NUM_LAYERS}L_{WINDOW_SIZE}W_{ACCELERATION_DATA_TYPE[0]} Loss")
plt.plot(train_loss, label='Train Loss')
plt.plot(val_loss, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Accuracy 그래프
plt.subplot(1, 2, 2)
plt.title(f"GRU_{INPUT_SIZE}I_{HIDDEN_SIZE}H_{NUM_LAYERS}L_{WINDOW_SIZE}W_{ACCELERATION_DATA_TYPE[0]} Accuracy")
plt.plot(train_accuracy[1:], label='Train Accuracy')
plt.plot(val_accuracy[1:], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# 마지막 Accuracy 점 찍기 및 텍스트 표시
last_epoch = len(train_accuracy) - 1

# Train accuracy
plt.scatter(last_epoch, train_accuracy[-1], color='blue')
plt.text(last_epoch, train_accuracy[-1],
         f"{train_accuracy[-1]:.4f}",
         color='black', ha='center')


# Validation accuracy
plt.scatter(last_epoch, val_accuracy[-1], color='orange')
plt.text(last_epoch, val_accuracy[-1],
         f"{val_accuracy[-1]:.4f}",
         color='black', ha='center')

# 저장 및 출력
plt.savefig(f"GRU_{INPUT_SIZE}I_{HIDDEN_SIZE}H_{NUM_LAYERS}L_{WINDOW_SIZE}W_{ACCELERATION_DATA_TYPE[0]}_GRAPH")
plt.show()

model(data.to(device, dtype = torch.float32)[0][0].unsqueeze(0).unsqueeze(1))

"""# 6. Downloading Model"""

# result = torch.jit.trace(model, data.permute(1, 0, 2).to(device, dtype = torch.float32))

# result.save(f"GRU_{INPUT_SIZE}I_{HIDDEN_SIZE}H_{NUM_LAYERS}L_{WINDOW_SIZE}W.pt")

# !pip install onnx

import torch.onnx

torch.onnx.export(
    model,
    data.permute(1, 0, 2).to(device, dtype=torch.float32),
    f"GRU_{INPUT_SIZE}I_{HIDDEN_SIZE}H_{NUM_LAYERS}L_{WINDOW_SIZE}W_{ACCELERATION_DATA_TYPE[0]}.onnx",
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'seq_len', 1: 'batch_size'},
    },
    opset_version=12
)